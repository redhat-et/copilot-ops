{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import openai\n",
    "import git\n",
    "import yaml\n",
    "import pathlib\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all of the directories under certified-operators/operators, go through their subdirectories and look at each manifests/*.clusterserviceversion.yaml file to extract the fields in .spec.install.spec.Deployments, and return those as a list\n",
    "def get_operator_deployments(operator_dir: str) -> list[dict]:\n",
    "  deployments = []\n",
    "  # go through each directory under certified-operators/operators\n",
    "  for dir in pathlib.Path(operator_dir).iterdir():\n",
    "    # skip if not a directory \n",
    "    if not dir.is_dir():\n",
    "      continue\n",
    "    # go through each subdirectory under the current directory\n",
    "    for subdir in dir.iterdir():\n",
    "      # skip if not a directory\n",
    "      if not subdir.is_dir():\n",
    "        continue\n",
    "      # look at each manifests/*.clusterserviceversion.yaml file\n",
    "      for file in subdir.glob('manifests/*.clusterserviceversion.yaml'):\n",
    "        # parse the yaml file\n",
    "        with open(file, 'r') as f:\n",
    "          yaml_data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        # extract the spec.install.spec.Deployments fields\n",
    "        if 'spec' in yaml_data and 'install' in yaml_data['spec'] and 'spec' in yaml_data['spec']['install'] and 'deployments' in yaml_data['spec']['install']['spec']:\n",
    "          deploy = {\n",
    "            'operatorName': yaml_data['metadata']['name'],\n",
    "            'deployments': yaml_data['spec']['install']['spec']['deployments']\n",
    "          }\n",
    "          # return the list of deployments\n",
    "          deployments.append(deploy)\n",
    "  return deployments\n",
    "\n",
    "\n",
    "deployments = get_operator_deployments('certified-operators/operators')\n",
    "# deployments\n",
    "\n",
    "# dump all of the deployments to a file titled deployments.yaml\n",
    "with open('deployments.yaml', 'w') as f:\n",
    "  yaml.dump(deployments, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sample set of training data for OpenAI in a JSONL format like this: \n",
    "completions = [\n",
    "  {\n",
    "    \"prompt\": \"# deploy a ConfigMap named my-config-map\\nKind: ConfigMap\",\n",
    "    \"completion\": \"\\nmetadata:\\n\\tname: my-config-map\\nspec:\\n\\tmy-data: this is my data\\n\"\n",
    "  },\n",
    "  {\n",
    "    \"prompt\": \"# deploy a Service named my-service\\nKind: Service\",\n",
    "    \"completion\": \"\\nmetadata:\\n\\tname: my-service\\nspec:\\n\\tports:\\n\\t- port: 80\\n\\t- port: 443\\n\"\n",
    "  }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "# go through each directory in completions/ and obtain the representation for completion.yml and prompt.yml, then place them into a dict and append it to the training data list\n",
    "for dir in pathlib.Path('completions/').iterdir():\n",
    "\t# skip if not a directory\n",
    "\tif not dir.is_dir():\n",
    "\t\tcontinue\n",
    "\tsample = {\n",
    "\t\t'prompt': '',\n",
    "\t\t'completion': ''\n",
    "\t}\n",
    "\t# read the contents of completion.yml into a string\t\t\n",
    "\twith open(dir / 'completion.yml', 'r') as f:\n",
    "\t\tsample['completion'] = f.read()\n",
    "\n",
    "\t# read the contents of prompt.yml into a string\n",
    "\twith open(dir / 'prompt.yml', 'r') as f:\n",
    "\t\tsample['prompt'] = f.read()\n",
    "\t# append the dict to the training data list\n",
    "\ttraining_data.append(sample)\n",
    "\n",
    "# output the training data into a json file \n",
    "with open('training_data.jsonl', 'w') as f:\n",
    "\tjson.dump(training_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of training data for openai based on the deployments extracted\n",
    "training_data = []\n",
    "\n",
    "# process the list of deployments in deployments.yaml\n",
    "with open('deployments.yaml', 'r') as f:\n",
    "\tdeployments = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# for each deployment, extract the operatorName and the deployments fields\n",
    "for deployment in deployments:\n",
    "\tprompt = '# deploy a Deployment named ' + deployment['operatorName'] + '\\nKind: Deployment'\n",
    "\t\n",
    "\t# format each deployment dict in the deployments field into a string\n",
    "\tdeployment_strs = [yaml.dump(d, default_flow_style=False) for d in deployment['deployments']]\n",
    "\n",
    "\t# join the deployments fields into a string separated by '---'\n",
    "\tcompletion = '\\n---\\n'.join(deployment_strs)\n",
    "\t\n",
    "\t# append the test data into our training_data set\n",
    "\ttraining_data.append({\n",
    "\t\t'prompt': prompt,\n",
    "\t\t'completion': completion\n",
    "\t})\n",
    "\n",
    "# dump the training data into a json file\n",
    "with open('training_data.json', 'w') as f:\n",
    "\tjson.dump(training_data, f)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41cadbe7d55b88ec4638517af0d8172bb59c32cb76bc9cb4d55a67dd7cbdae85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
