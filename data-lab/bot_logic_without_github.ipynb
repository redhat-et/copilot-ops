{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Examples\n",
    "\n",
    "We will use the following structure to process examples:\n",
    "1. Read the `examples` directory to get a list of all the example directories\n",
    "2. For each `example`, do the following:\n",
    "\t1. Gather the list of issues in the `issues` directory\n",
    "\t2. For each issue:\n",
    "\t\t1. gather the relevant files from the `files` directory\n",
    "\t\t2. Generate a prompt based on the issue & files\n",
    "\t\t3. Try and retrieve a completion from OpenAI's completion endpoint:\n",
    "\t\t\t- If successful:\n",
    "\t\t\t\t1. Gather the updated files, write their contents to the original files in `files`\n",
    "\t\t\t\t2. Create a copy of the completed files in the `completions` directory \n",
    "\t\t\t- Otherwise, stop processing the issues\n",
    "\t3. Write the last successfully processed issue to a `last-processed` file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading File Data\n",
    "We'll use an `examples` directory to describe our scenarios. Every scenario consists of a directory called `files` containing the initial files that we'll be referencing, and a `issues` directory consisting of subdirectories named by the issue numbers, e.g. `issues/1`, `issues/2`, etc. Under each subdirectory, there is an `issue.md` file describing the changes to be made, and a `completions` directory where the files will be written to after being updated.\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "last-processed.json\n",
    "files/\n",
    "\tREADME.md\n",
    "\tindex.js\n",
    "\tpackage.json\n",
    "\tpackage-lock.json\n",
    "\tgenerated-files/\n",
    "\t\tfile-12345.yaml\n",
    "\t\tnfs-server-config.yaml\n",
    "\t\tnfs-pvc.yaml\n",
    "issues/\n",
    "\t1/\n",
    "\t\tissue.md\n",
    "\t\tcompletions/\n",
    "\t\t\tindex.js\n",
    "\t\t\tpackage.json\n",
    "\t2/\n",
    "\t\tissue.md\n",
    "\t\tcompletions/\n",
    "\t\t\tREADME.md\n",
    "\t\t\tpackage-lock.json\n",
    "\t3/\n",
    "\t\tissue.md\n",
    "\t\tcompletions/\n",
    "\t\t\tREADME.md\n",
    "\t\t\tindex.js\n",
    "\t\t\tpackage.json\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// declare our variables up here\n",
    "let prompt, files, issue, i, examples;\n",
    "const OPENAI_API_URL = 'https://api.openai.com/v1/engines/code-davinci-001/completions';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// import libraries\n",
    "const path = require('path');\n",
    "const fs = require('fs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// list out the contents of the current directory\n",
    "let localFiles = fs.readdirSync('./examples');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Issues\n",
    "\n",
    "Issues provide us with critical information about how exactly to generate files.\n",
    "There are two scenarios that could happen:\n",
    "\n",
    "1. The issue references files by including the syntax `@filetag:/path/to/file`, at which point we assume that the issue wants a modification to the existing files, rather than an entirely new generation\n",
    "2. No files are referenced, in which case we attempt to generate new files that match the issue's specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// return a map of {fileName => {path: path, content: content}}\n",
    "const getFilesFromIssue = (issue) => {\n",
    "\t// extract a map of the files from the issue based on the following regex:\n",
    "\t// /`(@([a-zA-Z0-9_\\-]+):(.+))`/g\n",
    "\tconst fileRegex = /`(@([a-zA-Z0-9_\\-]+):(.+))`/g;\n",
    "\t// create a map from the filename to the filepath\n",
    "\tconst fileMap = new Map();\n",
    "\t// extract the string from group 3 of the regex\n",
    "\tlet match;\n",
    "\twhile (match = fileRegex.exec(issue)) {\n",
    "\t\tlet [name, path] = [match[2], match[3]];\n",
    "\t\tif (!fileMap.has(name)) {\n",
    "\t\t\t// define the file object here \n",
    "\t\t\tfileMap.set(name, {\n",
    "\t\t\t\tpath: path,\n",
    "\t\t\t\tcontent: '',\n",
    "\t\t\t\tupdatedContent: '',\n",
    "\t\t\t});\n",
    "\t\t} else {\n",
    "\t\t\tconsole.error(`duplicate file name ${name}`);\n",
    "\t\t}\n",
    "\t}\n",
    "\treturn fileMap;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let getFilenamesFromIssue;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populating Files\n",
    "\n",
    "When the issue references files, we can obtain their filepath through regex, and subsequently search for the files in attempts to populate them via their `path` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const populateFiles = (fileMap, rootDir) => {\n",
    "\t// look through the fileMap and read the contents of the file at the given path\n",
    "\tfor (const [_, file] of fileMap) {\n",
    "\t\tlet searchPath = path.join(rootDir, file.path);\n",
    "\t\tfile.content = fs.readFileSync(searchPath, 'utf8');\n",
    "\t}\n",
    "\treturn fileMap;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let getIssuesForDirectory;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Issues From a Directory\n",
    "\n",
    "With each directory we look at, we go through the contents of the `issues` directory, which contains statements regarding modifications that should be made to the files.\n",
    "\n",
    "We then observe the value of `lastProcessed` in `last-processed.json`, and if it's not present, we start at the first issue.\n",
    "\n",
    "Each issue is processed in the ordering of its number in the `issues` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Function: getIssuesForDirectory]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getIssuesForDirectory = (dir) => {\n",
    "\t/* return a list of issue objects of the form: \n",
    "\t\t{\n",
    "\t\t\trelevantFiles: string[],\n",
    "\t\t\tcontent: string,\n",
    "\t\t\tissueNumber: number\n",
    "\t\t}\n",
    "\t*/ \n",
    "\tlet issues = fs.readdirSync(dir).map((issueNo) => {\n",
    "\t\tlet issuePath = path.join(dir, issueNo);\n",
    "\t\tlet issue = fs.readFileSync(path.join(issuePath, 'issue.md'), 'utf8');\n",
    "\t\treturn {\n",
    "\t\t\trelevantFiles: getFilesFromIssue(issue),\n",
    "\t\t\tcontent: issue,\n",
    "\t\t\t// convert the issueNo to a number\n",
    "\t\t\tissueNumber: parseInt(issueNo)\n",
    "\t\t};\n",
    "\t});\n",
    "\t// sort the issues by issue number\n",
    "\tissues.sort((a, b) => a.issueNumber - b.issueNumber);\n",
    "\treturn issues;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the prompt\n",
    "\n",
    "We build a new prompt for each issue depending on whether or not it has referenced any files.\n",
    "\n",
    "When no files are referenced, we build an issue using the following structure:\n",
    "\n",
    "```\n",
    "# Preamble defining the document\n",
    "1. Description of the issue\n",
    "2. A list of new files that are created to address the issue\n",
    "```\n",
    "\n",
    "On the contrary, files being referenced calls for the following structure:\n",
    "```\n",
    "# Preamble defining the document\n",
    "1. Description of the issue\n",
    "2. The contents of the files being referenced, prefixed by their `@filetag`\n",
    "3. The files after being updated to address the issue of #1, prefixed by their `@filetag`\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let buildPrompt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Function: buildPrompt]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// @issue: string\n",
    "// @files: map of {fileName: string => {path: string, content: string, updatedContent: string}}\n",
    "buildPrompt = (issue, files) => {\n",
    "\t// read the prefix from 'prefix.md'\n",
    "\tlet prefix, prompt;\n",
    "\t// if files is empty, we use the new file prefix\n",
    "\tif (files.size === 0) {\n",
    "\t\tprefix = fs.readFileSync('./new-prefix.md', 'utf8');\n",
    "\t\tprompt = `${prefix}\n",
    "\n",
    "## 1. Description of issue:\n",
    "${issue}\n",
    "\n",
    "## 2. New files:\\n`;\n",
    "\t} else {\n",
    "\t\tprefix = fs.readFileSync('./update-prefix.md', 'utf8');\n",
    "\t\tprompt = `${prefix}\n",
    "\t## 1. Description of issues:\n",
    "\t${issue}\n",
    "\n",
    "\t## 2. Original files:\n",
    "\t`;\n",
    "\n",
    "\t\ti = 0;\n",
    "\t\tfor (const [fileName, file] of files) {\n",
    "\t\t\tprompt += `# @${fileName}\\n${file.content}\\n`;\n",
    "\t\t\t// only place the delimiting string if in-between files\n",
    "\t\t\tif (files.size > 1 && i < files.size - 1) {\n",
    "\t\t\t\tprompt += '---\\n';\n",
    "\t\t\t}\n",
    "\t\t\ti++;\n",
    "\t\t}\n",
    "\n",
    "\t\tprompt += `\n",
    "\t## 3. Updated files:\n",
    "\t`;\n",
    "\t}\n",
    "\treturn prompt;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating Files\n",
    "\n",
    "We retrieve a completion from OpenAI's completion endpoint and split the files up by a '---' delimiter,\n",
    "then we'll match them to their corresponding files.\n",
    "\n",
    "Let's define a few functions to help us with this. We'll bring in the `axios` package to make our HTTP requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let completionToFiles, getCompletion;\n",
    "var axios = require('axios');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var yaml = require('js-yaml');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the Completion From OpenAI Into Files\n",
    "\n",
    "After OpenAI returns a completion for a given issue, we'll then need to parse the contents and transform it back into a useful format which can be mapped to the files.\n",
    "\n",
    "At this point, there are two scenarios:\n",
    "1. OpenAI returned a nice response (hooray!)\n",
    "2. OpenAI has returned a bunch of junk\n",
    "\n",
    "When OpenAI returns something nice, the format for YAMLs will be the following or existing files:\n",
    "```yaml\n",
    "# @bobfile \n",
    "kind: Human\n",
    "metadata:\n",
    "\tname: bob\n",
    "\tage: 24\n",
    "\tnamespace: bobville\n",
    "```\n",
    "\n",
    "For new files:\n",
    "```yaml\n",
    "kind: Human\n",
    "metadata:\n",
    "\tname: bob\n",
    "\tage: 24\n",
    "\tnamespace: bobville\n",
    "```\n",
    "\n",
    "But on junk responses, we don't know what we'll get. \n",
    "To circumvent this, we attempt to process the response by trying to parse it as YAML, and if we can't, we'll assume it's a string and just return it.\n",
    "We check if it's junk by stripping out all whitespaces and seeing if the length is 0, if not then there are still contents & we should save them. This isn't foolproof, but it's a good first approximation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Function: completionToFiles]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// process the completion & place it into the files' updatedContent field\n",
    "completionToFiles = (completion, files) => {\n",
    "\tlet completions = completion.split('---');\n",
    "\t// go through the list of completions, extract the filename and set the updated content\n",
    "\tfor (const cmpltn of completions) {\n",
    "\t\t// extract the file tag from the completion\n",
    "\t\tconst fileTagRegex = /#\\s*\\@(.+)/g;\n",
    "\t\tconst match = fileTagRegex.exec(cmpltn);\n",
    "\t\tif (match !== null) {\n",
    "\t\t\tconst fileTag = match[1];\n",
    "\t\t\tif (files.has(fileTag)) {\n",
    "\t\t\t\t// find the line containing the fileTag and remove all lines up to and including the fileTag \n",
    "\t\t\t\tconst lines = cmpltn.split('\\n');\n",
    "\t\t\t\tlet i = 0;\n",
    "\t\t\t\tfor (const line of lines) {\n",
    "\t\t\t\t\ti++;\n",
    "\t\t\t\t\tif (line.includes(fileTag)) {\n",
    "\t\t\t\t\t\tbreak;\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t\t// remove the lines from the completion\n",
    "\t\t\t\tconst newCompletion = lines.slice(i).join('\\n');\n",
    "\t\t\t\t// set the updated content\n",
    "\t\t\t\tfiles.get(fileTag).updatedContent = newCompletion;\n",
    "\t\t\t}\n",
    "\t\t} else {\n",
    "\t\t\t// check if the file is empty by stripping all whitespace & seeing if any characters are left\n",
    "\t\t\tconst stripped = cmpltn.replace(/\\s/g, '');\n",
    "\t\t\tif (stripped.length === 0) {\n",
    "\t\t\t\t// skip this\n",
    "\t\t\t\tcontinue;\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t// create a new file & map it to the name found in .metadata.name\n",
    "\t\t\tconst yamlResource = yaml.load(cmpltn);\n",
    "\t\t\t// try to retrieve .metadata.name, else just default to a random name\n",
    "\t\t\t// use a random integer\n",
    "\n",
    "\t\t\tlet name = yamlResource.metadata.name || `file-${Math.floor(Math.random() * 10000000000)}`;\n",
    "\t\t\t// if the files map already has an object with this name, keep generating a new one\n",
    "\t\t\twhile (files.has(name)) {\n",
    "\t\t\t\tname = `file-${Math.floor(Math.random() * 10000000000)}`;\n",
    "\t\t\t}\n",
    "\t\t\tfiles.set(name, {\n",
    "\t\t\t\tpath: `generated-files/${name}.yaml`,\n",
    "\t\t\t\tcontent: cmpltn,\n",
    "\t\t\t\tupdatedContent: cmpltn\n",
    "\t\t\t});\n",
    "\t\t}\n",
    "\t}\n",
    "};\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Completions\n",
    "\n",
    "This is the easiest part of the process, we just send our prompt over to OpenAI's completions endpoint and await a successful response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AsyncFunction: getCompletion]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// to create the completion\n",
    "getCompletion = async (prompt, maxTokens, stopSequences) => {\n",
    "\tstopSequences = stopSequences || ['####',];\n",
    "\tconst headers = {\n",
    "\t\t// get OPENAI_API_KEY from env\n",
    "\t\t\"Authorization\": `Bearer ${process.env.OPENAI_API_KEY}`,\n",
    "\t\t\"Content-Type\": \"application/json\",\n",
    "\t};\n",
    "\t// console.log(\"headers\", headers);\n",
    "\tconst body = {\n",
    "\t\tprompt: prompt,\n",
    "\t\tmax_tokens: maxTokens | 512,\n",
    "\t\tstop: stopSequences,\n",
    "\t\ttemperature: 0,\n",
    "\t\ttop_p: 1,\n",
    "\t\tfrequency_penalty: 0,\n",
    "\t\tpresence_penalty: 0,\n",
    "\t};\n",
    "\tlet completion;\n",
    "\n",
    "\t// request the openai api using axios\n",
    "\tawait axios.post(OPENAI_API_URL, body, { headers }).then(async (response) => {\n",
    "\t\t// update the object with the competion result\n",
    "\t\tif (response.status == 200 && response.data.choices) {\n",
    "\t\t\tif (response.data.choices.length > 0) {\n",
    "\t\t\t\tcompletion = response.data.choices[0].text;\n",
    "\t\t\t} else {\n",
    "\t\t\t\tconsole.error(\"no completion found\");\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t});\n",
    "\treturn completion;\n",
    "};\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const updateFilesFromCompletion = async (files, prompt, maxTokens) => {\n",
    "\tconst completion = await getCompletion(prompt, maxTokens, ['####',]);\n",
    "\tcompletionToFiles(completion, files);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let writeFilesToCompletionsDir;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Files From Completion\n",
    "\n",
    "Once we have obtained a completion, we'll need to save the new contents into the `completions` for our current issue, and copy the results into the original `files` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Function: writeFilesToCompletionsDir]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// filesMap: map of {fileName: string => {path: string, content: string, updatedContent: string}}\n",
    "// basePath: string\n",
    "writeFilesToCompletionsDir = (filesMap, basePath) => {\n",
    "\t\t// delete the completions directory if it exists\n",
    "\t\tif (fs.existsSync(path.join(basePath, 'completions'))) {\n",
    "\t\t\tfs.rmSync(path.join(basePath, 'completions'), { recursive: true });\n",
    "\t\t}\n",
    "\n",
    "\t\t// write the updated files into the completions directory using their same path as the original files\n",
    "\t\tfor (const [_, file] of filesMap) {\n",
    "\t\t\tlet outputPath = path.join(basePath, 'completions', file.path);\n",
    "\t\t\tfs.mkdirSync(path.dirname(outputPath), { recursive: true });\n",
    "\t\t\t// write the file and create parent directories, if needed\n",
    "\t\t\tfs.writeFileSync(outputPath, file.updatedContent);\n",
    "\t\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let writeUpdatedContentToFiles;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Function: writeUpdatedContentToFiles]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeUpdatedContentToFiles = (filesMap, basePath) => {\n",
    "\t// go through each file and write the updated content to the file\n",
    "\tfor (const [filename, file] of filesMap) {\n",
    "\t\tlet outputPath = path.join(basePath, 'files', file.path);\n",
    "\t\t// create the base directory if it doesn't exist\n",
    "\t\tfs.mkdirSync(path.dirname(outputPath), { recursive: true });\n",
    "\t\tfs.writeFileSync(outputPath, file.updatedContent, { recursive: true });\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let populateFileMap;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Function: populateFileMap]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populateFileMap = (filesMap, basePath) => {\n",
    "\t// populate the example's files from the main files\n",
    "\tfor (const [_, file] of filesMap) {\n",
    "\t\t// read the file from the file.path and set the content\n",
    "\t\tlet filePath = path.join(basePath, file.path);\n",
    "\t\tfile.content = fs.readFileSync(filePath, 'utf8');\n",
    "\t}\t\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the file updater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let processExample;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Examples\n",
    "\n",
    "Now we just bring all of the steps from above together:\n",
    "1. Read the `examples` directory to get a list of all the example directories\n",
    "2. For each `example`, do the following:\n",
    "\t1. Gather the list of issues in the `issues` directory\n",
    "\t2. For each issue:\n",
    "\t\t1. gather the relevant files from the `files` directory\n",
    "\t\t2. Generate a prompt based on the issue & files\n",
    "\t\t3. Try and retrieve a completion from OpenAI's completion endpoint:\n",
    "\t\t\t- If successful:\n",
    "\t\t\t\t1. Gather the updated files, write their contents to the original files in `files`\n",
    "\t\t\t\t2. Create a copy of the completed files in the `completions` directory \n",
    "\t\t\t- Otherwise, stop processing the issues\n",
    "\t3. Write the last successfully processed issue to a `last-processed` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AsyncFunction: processExample]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processExample = async (baseDir) => {\n",
    "\t// first check to see if a last-processed.json file exists\n",
    "\tlet lastProcessedFile = path.join(baseDir, 'last-processed.json');\n",
    "\tlet lastProcessed;\n",
    "\tif (fs.existsSync(lastProcessedFile)) {\n",
    "\t\tlastProcessed = JSON.parse(fs.readFileSync(lastProcessedFile, 'utf8'));\n",
    "\t} else {\n",
    "\t\tlastProcessed = {\n",
    "\t\t\tissueNumber: 0,\n",
    "\t\t};\n",
    "\t}\n",
    "\n",
    "\t// load the issues \n",
    "\tlet issues = getIssuesForDirectory(path.join(baseDir, 'issues'));\n",
    "\t\n",
    "\t// we need to process all issues whose number is greater than the last processed issue number\n",
    "\tlet issuesToProcess = issues.filter((issue) => issue.issueNumber > lastProcessed.issueNumber);\n",
    "\n",
    "\n",
    "\ttry {\n",
    "\t\t// process each issue until failure or completion\n",
    "\t\tfor (let issue of issuesToProcess) {\n",
    "\t\t\t// clean out all of the issue's files \n",
    "\t\t\tlet issuePath = path.join(baseDir, 'issues', issue.issueNumber.toString());\n",
    "\t\t\t\n",
    "\t\t\t// delete everything recursively EXCEPT issue.md\n",
    "\t\t\tfor (const file of fs.readdirSync(issuePath)) {\n",
    "\t\t\t\tif (file !== 'issue.md') {\n",
    "\t\t\t\t\tfs.rmSync(path.join(issuePath, file), { recursive: true });\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t\t// split the prompt based on whether the prompt references files\n",
    "\t\t\t// populate the issue's files \n",
    "\t\t\tpopulateFileMap(issue.relevantFiles, path.join(baseDir, 'files'));\n",
    "\n",
    "\n",
    "\t\t\t// generate a prompt from the issue's content and files\n",
    "\t\t\t// write the prompt to a file\n",
    "\t\t\tlet initialPrompt = buildPrompt(issue.content, issue.relevantFiles);\n",
    "\t\t\tfs.writeFileSync(path.join(issuePath, 'prompt.md'), initialPrompt);\n",
    "\n",
    "\t\t\t// obtain a completion & write it to file\n",
    "\t\t\tlet completion = await getCompletion(initialPrompt, 512, ['####','## End of document']);\n",
    "\t\t\tfs.writeFileSync(path.join(issuePath, 'completion.md'), [initialPrompt, completion].join(''), );\n",
    "\n",
    "\t\t\t// convert the completion to the issue's files\n",
    "\t\t\tcompletionToFiles(completion, issue.relevantFiles);\t\t\t\n",
    "\t\t\twriteFilesToCompletionsDir(issue.relevantFiles, issuePath);\n",
    "\t\t\twriteUpdatedContentToFiles(issue.relevantFiles, baseDir);\n",
    "\n",
    "\t\t\t// update the last processed issue number\n",
    "\t\t\tlastProcessed.issueNumber = issue.issueNumber;\n",
    "\t\t}\n",
    "\t} catch(e) {\n",
    "\t\tconsole.log(e);\n",
    "\t} finally {\n",
    "\t\t// write the last processed issue number to a file\n",
    "\t\tfs.writeFileSync(lastProcessedFile, JSON.stringify(lastProcessed));\n",
    "\t}\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let processExamples;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AsyncFunction: processExamples]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processExamples = async () => {\n",
    "\tconst examplesDir = './examples';\n",
    "\tconst examples = fs.readdirSync(examplesDir);\n",
    "\tfor (const dirname of examples) {\n",
    "\t\tconsole.log('processing example: ', dirname);\n",
    "\t\tlet exampleDir = path.join(examplesDir, dirname);\n",
    "\t\t// read the last issue processed from the example directory\n",
    "\t\tawait processExample(exampleDir);\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing example:  request-more-cpu\n",
      "filePath: examples/request-more-cpu/files/cluster-scope/base/core/namespaces/training-model/kustomization.yaml\n",
      "basePath: examples/request-more-cpu/files\n",
      "file.path: cluster-scope/base/core/namespaces/training-model/kustomization.yaml\n",
      "filePath: examples/request-more-cpu/files/cluster-scope/base/core/namespaces/training-model/resourcequota.yaml\n",
      "basePath: examples/request-more-cpu/files\n",
      "file.path: cluster-scope/base/core/namespaces/training-model/resourcequota.yaml\n",
      "relevantFiles:  Map(2) {\n",
      "  'kustomization' => {\n",
      "    path: 'cluster-scope/base/core/namespaces/training-model/kustomization.yaml',\n",
      "    content: 'apiVersion: kustomize.config.k8s.io/v1beta1\\n' +\n",
      "      'kind: Kustomization\\n' +\n",
      "      'resources:\\n' +\n",
      "      '    - namespace.yaml\\n' +\n",
      "      '    - resourcequota.yaml\\n' +\n",
      "      'components:\\n' +\n",
      "      '    - ../../../../components/project-admin-rolebindings/octo-training-model\\n' +\n",
      "      '    - ../../../../components/limitranges/default\\n' +\n",
      "      'namespace: training-model\\n' +\n",
      "      '\\n' +\n",
      "      '\\n',\n",
      "    updatedContent: ''\n",
      "  },\n",
      "  'resourcequota' => {\n",
      "    path: 'cluster-scope/base/core/namespaces/training-model/resourcequota.yaml',\n",
      "    content: 'apiVersion: v1\\n' +\n",
      "      'kind: ResourceQuota\\n' +\n",
      "      'metadata:\\n' +\n",
      "      '  name: training-model-custom\\n' +\n",
      "      'spec:\\n' +\n",
      "      '  hard:\\n' +\n",
      "      \"    limits.cpu: '28'\\n\" +\n",
      "      '    limits.memory: 32Gi\\n' +\n",
      "      \"    requests.cpu: '28'\\n\" +\n",
      "      '    requests.memory: 32Gi\\n' +\n",
      "      '    requests.storage: 100Gi',\n",
      "    updatedContent: ''\n",
      "  }\n",
      "}\n",
      "Error: ENOENT: no such file or directory, open './update-prefix.md'\n",
      "    at Object.openSync (node:fs:585:3)\n",
      "    at Object.readFileSync (node:fs:453:35)\n",
      "    at buildPrompt (evalmachine.<anonymous>:16:15)\n",
      "    at processExample (evalmachine.<anonymous>:40:24)\n",
      "    at processExamples (evalmachine.<anonymous>:8:9)\n",
      "    at evalmachine.<anonymous>:13:2\n",
      "    at Script.runInThisContext (node:vm:129:12)\n",
      "    at Object.runInThisContext (node:vm:305:38)\n",
      "    at run ([eval]:1054:15)\n",
      "    at onRunRequest ([eval]:888:18) {\n",
      "  errno: -2,\n",
      "  syscall: 'open',\n",
      "  code: 'ENOENT',\n",
      "  path: './update-prefix.md'\n",
      "}\n",
      "processing example:  simple-prometheus-update\n",
      "filePath: examples/simple-prometheus-update/files/grafana/base/datasource.yaml\n",
      "basePath: examples/simple-prometheus-update/files\n",
      "file.path: grafana/base/datasource.yaml\n",
      "filePath: examples/simple-prometheus-update/files/grafana/base/grafana-route.yaml\n",
      "basePath: examples/simple-prometheus-update/files\n",
      "file.path: grafana/base/grafana-route.yaml\n",
      "relevantFiles:  Map(2) {\n",
      "  'file1' => {\n",
      "    path: 'grafana/base/datasource.yaml',\n",
      "    content: 'apiVersion: integreatly.org/v1alpha1\\n' +\n",
      "      'kind: GrafanaDataSource\\n' +\n",
      "      'metadata:\\n' +\n",
      "      '  name: datasource\\n' +\n",
      "      'spec:\\n' +\n",
      "      '  name: prometheus-grafanadatasource.yaml\\n' +\n",
      "      '  datasources:\\n' +\n",
      "      '    - name: Prometheus\\n' +\n",
      "      '    - access: proxy\\n' +\n",
      "      '      editable: true\\n' +\n",
      "      '      isDefault: true\\n' +\n",
      "      '      jsonData:\\n' +\n",
      "      \"        httpHeaderName1: 'Authorization'\\n\" +\n",
      "      '        timeInterval: 5s\\n' +\n",
      "      '        tlsSkipVerify: true\\n' +\n",
      "      '      name: Prometheus\\n' +\n",
      "      '      secureJsonData:\\n' +\n",
      "      \"        httpHeaderValue1: 'Bearer ${BEARER_TOKEN}'\\n\" +\n",
      "      '      type: prometheus\\n' +\n",
      "      \"      url: 'https://thanos-querier.openshift-monitoring.svc.cluster.local:9091'\",\n",
      "    updatedContent: ''\n",
      "  },\n",
      "  'file2' => {\n",
      "    path: 'grafana/base/grafana-route.yaml',\n",
      "    content: 'kind: Route\\n' +\n",
      "      'apiVersion: route.openshift.io/v1\\n' +\n",
      "      'metadata:\\n' +\n",
      "      '  name: grafana\\n' +\n",
      "      '  annotations:\\n' +\n",
      "      '    kubernetes.io/tls-acme: \"true\"\\n' +\n",
      "      'spec:\\n' +\n",
      "      '  host: grafana.operate-first.cloud\\n' +\n",
      "      '  to:\\n' +\n",
      "      '    kind: Service\\n' +\n",
      "      '    name: grafana-service\\n' +\n",
      "      '  port:\\n' +\n",
      "      '    targetPort: 3000',\n",
      "    updatedContent: ''\n",
      "  }\n",
      "}\n",
      "Error: ENOENT: no such file or directory, open './update-prefix.md'\n",
      "    at Object.openSync (node:fs:585:3)\n",
      "    at Object.readFileSync (node:fs:453:35)\n",
      "    at buildPrompt (evalmachine.<anonymous>:16:15)\n",
      "    at processExample (evalmachine.<anonymous>:40:24)\n",
      "    at processExamples (evalmachine.<anonymous>:8:9)\n",
      "    at processTicksAndRejections (node:internal/process/task_queues:96:5) {\n",
      "  errno: -2,\n",
      "  syscall: 'open',\n",
      "  code: 'ENOENT',\n",
      "  path: './update-prefix.md'\n",
      "}\n",
      "processing example:  update-smaug\n",
      "relevantFiles:  Map(0) {}\n",
      "writing to:  examples/update-smaug/issues/1/completions/generated-files/nfs-provisioner.yaml\n",
      "writing to:  examples/update-smaug/issues/1/completions/generated-files/file-4998347428.yaml\n",
      "writing to:  examples/update-smaug/issues/1/completions/generated-files/file-8592510549.yaml\n",
      "updating file: \"nfs-provisioner\": generated-files/nfs-provisioner.yaml\n",
      "updating file: \"file-4998347428\": generated-files/file-4998347428.yaml\n",
      "updating file: \"file-8592510549\": generated-files/file-8592510549.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "undefined"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \\\r"
     ]
    }
   ],
   "source": [
    "$$.async();\n",
    "{\n",
    "\trod = (function rod() {\n",
    "\t\tconst chars = \"|/-\\\\\";\n",
    "\t\tlet i=0;\n",
    "\t\treturn function() {\n",
    "\t\t\t\ti= (i+1) % 4;\n",
    "\t\t\t\t// We need to use process.stdout.write since console.log automatically adds a \\n to the end of lines\n",
    "\t\t\t\tprocess.stdout.write(` ${chars[i]}\\r`);\n",
    "\t\t}\n",
    "\t})();\n",
    "\tsetInterval(rod, 250);\t\n",
    "\tprocessExamples();\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "16.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
